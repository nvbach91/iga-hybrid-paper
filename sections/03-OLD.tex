When it comes to representing concepts in an RDF knowledge base, the modelers have three common options, and they choose from among them based on their use cases. The first one is to use ontology classes and connect them with properties which represent the relationships between themselves and their instances. This approach creates the ontology schema with the necessary overall rules for the entire knowledge base to operate and to be queried in a meaningful way and more effectively. The result is basically a generalized conceptual model, which includes abstractions of things. The second approach involves organizing data instances as code individuals, usually into a structured unit called a code list, that can be used directly via referencing. The third option involves creating KG individuals and ad-hoc object properties without prior definitions of their types, and these properties are then documented for repeated use. Hence, it is harder to ensure the completeness of query results without the knowledge of the property itself.

Let us take a look at the differences among these three expected approaches for each different consideration modeling problem when modeling a concept for a RDF knowledge base, see Table \ref{tab:comparison}. 

The first modeling problem is creating OWL meta-model entities that correspond to abstract classes, types or kinds. In the first approach, the conceptual representation for such entities is a class (\textit{owl:Class}, \textit{rdfs:Class}, etc.). In the second approach, entities are represented by individuals, namely instances of a class or, usually, of a SKOS concept. Also in OWL, these individuals are instances of \textit{owl:NamedIndividual}. In the third approach, entities are represented as individuals.
%, but as instances of the concept class, not as a subclass of that class. This approach is more straightforward as it simplifies and flatten the class structure to the point that.

The second modeling problem is linking from ontological instances, i.e., connecting the concept and its instance. In the first approach, the property \textit{rdf:type} is used to link an instance to its class, clearly stating that it is an instance of that class. In the second approach, the usual choice is the property \textit{skos:broader} that is used to assert a direct hierarchical link between two SKOS concepts. The inverse link property of the original property is the \textit{skos:narrower} property. They both denote a direct hierarchical link. For indirect hierarchical links between concepts, there are \textit{skos:broaderTransitive} and \textit{skos:narrowerTransitive}. Often though, as can be observed in many code lists, concepts are modeled without a hierarchy and they form a flat structure. In the third approach, the modelers can create arbitrary properties to link the concepts, e.g., :hasType, and reuse it in their own datasets.

The third modeling problem involves linking each concept to its type. In the first approach, there is no way to connect a class to a higher type, as we do not distinguish between different types of classes. In the second approach, a code individual is linked to a class that it instantiates using rdf:type. In the third approach, \textit{rdf:type} is also used, but not all individuals have their types.

The third modeling problem is that of representing a meta-type of a concept. In the first approach, a class does not have any type. In the second approach, \textit{owl:Class} is used to represent the type of the code. And in the third approach, \textit{owl:Class} is used, but there can be individuals that do not instantiate any classes, therefore none of them has a type.

The fourth modeling problem is that of linking concepts to their super concepts. The first approach makes use of the property rdfs:subClassOf; it states that all instances of one class are instances of the super class. The second approach uses \textit{skos:broader}, \textit{skos:broaderTransitive}; they state that the super concept is a concept, which is also an individual,  broader than the original concept. The third approach is similar to the second when it comes to the relationship between individuals, but, in certain cases, the linking properties may be created ad-hoc and typically with characteristic labels. The property \textit{rdf:type} is also used to link an individual to super concepts in the form of ontology classes, but it could lead to meta-level mixing, because there could be instances and types of  concepts linked using the same property.

The fifth modeling problem is that of representing concepts as the value of a property. The first approach requires punning, and  multiple properties could possibly be used. In the second approach, there is sometimes just one property per code list, e.g., \textit{skos:broader}, or a certain domain specific property to represent a relationship between codes. In the third approach, multiple properties may be used.

The sixth modeling problem involves the changing factor of concepts via, e.g., a validity period. In the first approach, changes are made in an irregular period, for the given version of the ontology. Also, old concepts may be kept with a `deprecated annotation' and linked with the new, replacing, concept. In the second approach, the validity period of a concept applies for the given edition of the code list, and changes are  usually made on a regular basis, e.g., annually, as these changes would reflect a kind of official release of codes. In the third approach, changes are made on an irregular basis, and  the validity cannot be established even when analyzing external resources.

